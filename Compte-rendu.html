<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>quarto-inputdfb9651b12eb346b</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="script_files/libs/clipboard/clipboard.min.js"></script>
<script src="script_files/libs/quarto-html/quarto.js"></script>
<script src="script_files/libs/quarto-html/popper.min.js"></script>
<script src="script_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="script_files/libs/quarto-html/anchor.min.js"></script>
<link href="script_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="script_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="script_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="script_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="script_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">
<style>
    .page-container {
        max-width: 800px;
        margin: 0 auto;
    }
    
    /* Justification du texte - Ne s'applique PAS à la page de garde */
    body:not(.page-container) main.content p {
        text-align: justify;
    }

    /* Force le centrage pour la page de garde */
    .cover-section * {
       text-align: center !important;
    }
    
    .tp-title {
        font-size: 1.8rem;
        margin-bottom: 2rem;
    }
    
    .auteur {
        font-size: 1.4rem;
    }
    
    .date {
        font-size: 1.2rem;
        margin-bottom: 1rem;
    }
    
    .logos {
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    
    .logo-left, .logo-right {
        flex: 0 0 150px;
    }
    
    .logo-left {
        text-align: left;
    }
    
    .logo-right {
        text-align: right;
    }
    
    .logo-left img, .logo-right img {
        max-width: 150px;
        height: auto;
        transform: translateY(-50px);
    }
    
    .nom-master p {
        margin: 0.2rem 0;
        font-size: 1.1rem;
    }
    
    .ligne {
        width: 60%;
        height: 1px;
        background-color: #000;
        margin: 2rem auto 3rem auto;
    }
</style>

<div class="page-container">
    <div class="cover-section">
        <h1 class="tp-title">TP3 - Support Vector Machine (SVM)</h1>
        
        <div class="auteur">AIGOIN Emilie</div>
        <div class="date">2025-2026</div>
        
        <div class="logos">
            <div class="logo-left">
                <img src="mise_en_page/Logo_SSD.png" alt="Logo SSD">
            </div>
            
            <div class="nom-master">
                <p>Université de Montpellier</p>
                <p>Master Statistique et Science des Données</p>
            </div>
            
            <div class="logo-right">
                <img src="mise_en_page/Logo_univMtp.png" alt="Logo Université Montpellier">
            </div>
        </div>
        
        <div class="ligne"></div>
    </div>
</div>

<br><br>



<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Sommaire</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction">1. Introduction</a>
  <ul>
  <li><a href="#objectif" id="toc-objectif">1.1. Objectif</a></li>
  <li><a href="#notations-et-formules" id="toc-notations-et-formules">1.2. Notations et formules</a></li>
  <li><a href="#méthode-support-vector-machine" id="toc-méthode-support-vector-machine">1.3. Méthode Support Vector Machine</a></li>
  </ul></li>
  <li><a href="#mise-en-oeuvre---iris" id="toc-mise-en-oeuvre---iris">2. Mise en oeuvre - Iris</a>
  <ul>
  <li><a href="#question-1." id="toc-question-1.">2.1. Question 1.</a></li>
  <li><a href="#question-2.-noyau-polynomial" id="toc-question-2.-noyau-polynomial">2.2. Question 2. Noyau polynomial</a></li>
  </ul></li>
  <li><a href="#mise-en-oeuvre---svm-gui" id="toc-mise-en-oeuvre---svm-gui">3. Mise en oeuvre - SVM GUI</a>
  <ul>
  <li><a href="#question-3." id="toc-question-3.">3.1. Question 3.</a></li>
  </ul></li>
  <li><a href="#mise-en-oeuvre---classification-de-visages" id="toc-mise-en-oeuvre---classification-de-visages">4. Mise en oeuvre - Classification de visages</a>
  <ul>
  <li><a href="#question-4." id="toc-question-4.">4.1. Question 4.</a></li>
  <li><a href="#question-5." id="toc-question-5.">4.2. Question 5.</a></li>
  <li><a href="#question-6." id="toc-question-6.">4.3. Question 6.</a></li>
  <li><a href="#question-7." id="toc-question-7.">4.4. Question 7.</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion">5. Conclusion</a></li>
  <li><a href="#sources" id="toc-sources">6. Sources</a></li>
  </ul>
</nav>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">1. Introduction</h2>
<section id="objectif" class="level3">
<h3 class="anchored" data-anchor-id="objectif">1.1. Objectif</h3>
<p>L’objectif de ce TP est de mettre en pratique la technique de classification Support Vector Machine (SVM) sur des données réelles et simulées au moyen du package <code>scikit-learn</code> et d’apprendre à contrôler les paramètres garantissant leur flexibilité.</p>
</section>
<section id="notations-et-formules" class="level3">
<h3 class="anchored" data-anchor-id="notations-et-formules">1.2. Notations et formules</h3>
<p>Nous rappelons les définitions, notations et formules suivantes :</p>
<ul>
<li><span class="math inline">\(\mathcal{Y}\)</span> : ensemble des étiquettes (labels), usuellement <span class="math inline">\(\mathcal{Y} = \{-1, 1\}\)</span> pour la classification binaire</li>
<li><span class="math inline">\(x = (x_1, \ldots, x_p) \in \mathcal{X} \subset \mathbb{R}^p\)</span> : une observation (ou exemple) décrite par <span class="math inline">\(p\)</span> variables</li>
<li><span class="math inline">\(\mathcal{D}_n = \{(x_i, y_i), i = 1, \ldots, n\}\)</span> : ensemble d’apprentissage contenant <span class="math inline">\(n\)</span> exemples étiquetés</li>
<li><span class="math inline">\(\hat{f} : \mathcal{X} \to \{-1, 1\}\)</span> : fonction de classification apprise à partir de <span class="math inline">\(\mathcal{D}_n\)</span></li>
</ul>
<p><strong>Overfitting (surapprentissage)</strong> : phénomène où le modèle mémorise les données d’entraînement au lieu d’apprendre des patterns généralisables, problème de généralisation et ne peut pas reconnaître d’autres données. Cela se traduit par une excellente performance sur les données d’entraînement mais une performance dégradée sur les données de test.</p>
</section>
<section id="méthode-support-vector-machine" class="level3">
<h3 class="anchored" data-anchor-id="méthode-support-vector-machine">1.3. Méthode Support Vector Machine</h3>
<p>Les Vector Support Machine (SVM) sont un ensemble de méthodes d’apprentissage supervisé utilisées pour la classification, la régression et la detection de valeurs abberantes.</p>
<p>Les SVM reposent sur deux idées clés : la notion de marge maximale (distance entre la frontière de séparation et les échantillons les plus proches) et celle de fonction de noyau (opérateur linéaire défini à l’aide d’une intégrale paramétrique sur certains espaces fonctionnels).</p>
<p>Leurs avantages sont qu’elles sont efficaces dans les espaces en grande dimension (lorsqu’il y a plus de variables que d’individus), plusieurs fonctions de noyaux peuvent être utilisées.</p>
<p>Cependant, les SVM ne fournissent pas directement d’estimations de probabilité, il faut les calculer à l’aide de validation croisée.</p>
</section>
</section>
<section id="mise-en-oeuvre---iris" class="level2">
<h2 class="anchored" data-anchor-id="mise-en-oeuvre---iris">2. Mise en oeuvre - Iris</h2>
<p>Nous commençons tout d’abbord par importer les packages qui nous serons nécessaires pour la suite de ce TP.</p>
<div id="10d86996" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importation des bibliothèques</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> svm_source <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils <span class="im">import</span> shuffle</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_lfw_people</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisation du scaler pour normaliser les données</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Ignorer les avertissements pour une sortie plus propre</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Style de graphiques</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'ggplot'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="question-1." class="level3">
<h3 class="anchored" data-anchor-id="question-1.">2.1. Question 1.</h3>
<p>Nous cherchons ici à développer un code qui va classifier la classe <span class="math inline">\(1\)</span> contre la classe <span class="math inline">\(2\)</span> du dataset <code>iris</code> en utilisant les deux premières variables et un noyau linéaire.</p>
<p>Pour cela, nous commençons par importer les données issues du jeu de données précédemment cité. Puis nous ne conservons que les deux premières variables.</p>
<div id="0cabcf9f" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Chargement du dataset Iris</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> datasets.load_iris()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> iris.data</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation des données (moyenne=0, écart-type=1)</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> iris.target</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sélection des données (que classes 1 et 2, avec les 2 premières variables)</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[y <span class="op">!=</span> <span class="dv">0</span>, :<span class="dv">2</span>]          <span class="co"># garde seulement les colonnes 0 et 1, exclut la classe 0</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y[y <span class="op">!=</span> <span class="dv">0</span>]              <span class="co"># Garde seulement les classes 1 et 2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Ensuite, nous devons laisser un quart des données de côté pour évaluer la performance en généralisation du modèle. Dans ces données, nous allons les séparer en un groupe d’entraînement (<span class="math inline">\(75\%\)</span>) et un groupe de test (<span class="math inline">\(25\%\)</span>). Pour ce faire, nous avons décidé d’utiliser la fonction <code>test_train_split</code> qui permet de mélanger automatiquement les données, ce qui est important pour éviter les biais (si les données iris sont ordonnées par classe par exemple). Puis nous avons fixé la graine comme <span class="math inline">\(42\)</span> afin d’assurer la reproductibilité.</p>
<div id="b78834e3" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Séparation train/test (75% train, 25% test)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                                                    y, </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.25</span>, </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) <span class="co"># graine</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Maintenant que nos données sont correctement mélangées et séparées aléatoirement, nous allons pouvoir évaluer la performance en généralisation du modèle à partir d’une <em>noyau linéaire</em>. Ce noyau permet de chercher une frontière de décision linéaire (droite en <span class="math inline">\(2\)</span>D).</p>
<p>Le l’hyperparamètre <span class="math inline">\(C\)</span> que nous devons choisir (le meilleur possible) est la marge, elle doit faire un compromis entre : - <span class="math inline">\(C\)</span> petit : marge large mais tolère plus d’erreurs. - <span class="math inline">\(C\)</span> grand : marge étroitre mais moins d’erreurs d’entraînement (risque d’overfitting).</p>
<div id="857a4e1e" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration de la recherche par grille pour trouver le meilleur C</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>parameters <span class="op">=</span> {<span class="st">'kernel'</span>: [<span class="st">'linear'</span>],               <span class="co"># noyau linéaire</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>              <span class="st">'C'</span>: <span class="bu">list</span>(np.logspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">200</span>))} <span class="co"># 200 valeurs (de 0,001 à 1000)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Création du modèle SVM et recherche du meilleur hyperparamètre</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>svr <span class="op">=</span> svm.SVC()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>clf_linear <span class="op">=</span> GridSearchCV(svr, parameters) <span class="co"># teste toutes les combinaisons de paramètres</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>clf_linear.fit(X_train, y_train)       <span class="co"># validation croisée</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des scores</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Generalization score for linear kernel: </span><span class="sc">%s</span><span class="st">, </span><span class="sc">%s</span><span class="st">'</span> <span class="op">%</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>      (clf_linear.score(X_train, y_train),   <span class="co"># score sur train</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>       clf_linear.score(X_test, y_test)))    <span class="co"># score sur test</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Generalization score for linear kernel: 0.7466666666666667, 0.68</code></pre>
</div>
</div>
<p>Nous savons qu’un bon modèle a un score de test proche de celui du train (ce qui veut dire qu’il n’y a pas d’overfitting).</p>
<p>Nous pouvons voir que le score pour le noyau linéaire des données d’entraînement est de <span class="math inline">\(0,75\)</span> (<span class="math inline">\(75\%\)</span>) alors que celui pour les données de test est de <span class="math inline">\(0,68\)</span> (<span class="math inline">\(68\%\)</span>).</p>
<p>La performance sur le train n’est pas excellente, en effet elle n’est que de <span class="math inline">\(75\%\)</span> ce qui indique que le modèle a un peu de mal à séparer les deux classes.</p>
<p>Cependant, le fait qu’il n’y ait qu’une diminution de <span class="math inline">\(7\%\)</span> entre les données d’entraînement et celles de test est plutôt encourageant. En effet, il est normal qu’il y ait une petite baisse sur des données qui n’ont jamais été vues.</p>
<p>Donc, comme les scores ne sont pas très élevés mais restent assez proches les uns des autres, nous pouvons en déduire que le modèle à noyau linéaire généralise moyennement. Le problème pourrait venir du fait que les classes ne se chevauchent probablement pas de manière linéaire et, comme nous utilisons un noyau linéaire, nous traçons une droite pour faire la séparation. De plus, peut être que les deux premières variables ne suffisent pas à bien discriminer les deux espèces.</p>
</section>
<section id="question-2.-noyau-polynomial" class="level3">
<h3 class="anchored" data-anchor-id="question-2.-noyau-polynomial">2.2. Question 2. Noyau polynomial</h3>
<p>Afin de comparer nos performances de généralisation du modèle entre plusieurs noyaux, nous allons faire un SVM basé sur un noyau polynomial.</p>
<div id="a42c52c9" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">""" # Configuration des hyperparamètres pour le noyau polynomial</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">Cs = list(np.logspace(-3, 3, 5)) # teste 5 valeurs de C (de 0.001 à 1000)</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">gammas = 10. ** np.arange(1, 2)</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">degrees = np.r_[1, 2, 3]         # polynômes de degrés 1, 2, 3</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration de la grille de recherche</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">parameters = {'kernel': ['poly'],   # noyau polynomial</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">              'C': Cs,              # 5 valeurs de C</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">              'gamma': gammas,      # 1 valeur (10.0)</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">              'degree': degrees}    # 3 valeurs</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Entraînement et sélection des meilleurs hyperparamètres</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">svr_poly = svm.SVC()    # vecteur vide</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">clf_poly = GridSearchCV(svr_poly, </span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">                        parameters) # teste les combinaisons (validation croisée)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">clf_poly.fit(X_train, y_train) # entraine les modèles et sélectionne le meilleur</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des meilleurs paramètres trouvés</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">print(clf_poly.best_params_)</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">print('Generalization score for polynomial kernel: %s, %s' %</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">      (clf_poly.score(X_train, y_train),</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">       clf_poly.score(X_test, y_test))) """</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>" # Configuration des hyperparamètres pour le noyau polynomial\nCs = list(np.logspace(-3, 3, 5)) # teste 5 valeurs de C (de 0.001 à 1000)\ngammas = 10. ** np.arange(1, 2)\ndegrees = np.r_[1, 2, 3]         # polynômes de degrés 1, 2, 3\n\n# Configuration de la grille de recherche\nparameters = {'kernel': ['poly'],   # noyau polynomial\n              'C': Cs,              # 5 valeurs de C\n              'gamma': gammas,      # 1 valeur (10.0)\n              'degree': degrees}    # 3 valeurs\n\n# Entraînement et sélection des meilleurs hyperparamètres\nsvr_poly = svm.SVC()    # vecteur vide\nclf_poly = GridSearchCV(svr_poly, \n                        parameters) # teste les combinaisons (validation croisée)\nclf_poly.fit(X_train, y_train) # entraine les modèles et sélectionne le meilleur\n\n# Affichage des meilleurs paramètres trouvés\nprint(clf_poly.best_params_)\nprint('Generalization score for polynomial kernel: %s, %s' %\n      (clf_poly.score(X_train, y_train),\n       clf_poly.score(X_test, y_test))) "</code></pre>
</div>
</div>
<p>Nous pouvons voir que nous obtenons exactement les mêmes scores pour le noyau polynomial que ceux que nous avions obtenu pour le noyau linéaire. En effet, nous pouvons voir des scores de <span class="math inline">\(0,75\)</span> pour le train et de <span class="math inline">\(0,68\)</span> pour les données de test.</p>
<p>Si nous regardons les hyperparamètres choisis par le modèle, nous pouvons voir que cette similarité n’est pas une coïncidence. En effet, elle s’explique par le choix des hyperparamètres optimaux sélectionnées par <code>GridSearchCV</code> pour le noyau polynomial.</p>
<p>Le paramètre important à regarder ici est le degré. Nous pouvons voir que c’est un noyau polynomial de degré <span class="math inline">\(1\)</span> qui a été choisi, ce qui équivalent à un noyau linéaire et c’est donc pour cela que nous obtenons les mêmes résultats au niveau des scores.</p>
<p>Ainsi, cette sélection automatique du degré <span class="math inline">\(1\)</span> par la validation croisée indique que la frontière de décision optimale pour séparer les classes <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span> d’Iris (avec les deux premières variables) est effectivement bien linéaire. Les polynômes de degrés supérieurs testés n’ont pas apporté d’amélioration, probablement car ils introduisent plus de complexité qui mène au surapprentissage sur cet ensemble de données.</p>
<p>Cela suggère que, dans l’espace défini par les deux premières variables, les données de ces deux classes d’Iris présentnet une structure essentiellement linéaire, ce qui justifie l’efficacité du noyau linéaire pour ce problème de classification.</p>
<p>Afin de vérifier ces résultats, nous allons les tracer en utilisant <code>frontiere</code>.</p>
<div id="d4c83bff" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">""" # Visualisation des frontières de décision (svm_source.py)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">def f_linear(xx):</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    return clf_linear.predict(xx.reshape(1, -1))</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">def f_poly(xx):</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    return clf_poly.predict(xx.reshape(1, -1))</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Création des graphiques comparatifs</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">plt.ion()</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">plt.figure(figsize=(15, 5))</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique 1 : données originales</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">plt.subplot(131)</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">plot_2d(X, y)</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title("iris dataset")</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique 2 : frontière avec noyau linéaire</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co">plt.subplot(132)</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co">frontiere(f_linear, X, y)</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title("linear kernel")</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique 3 : frontière avec noyau polynomial</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co">plt.subplot(133)</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co">frontiere(f_poly, X, y)</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title("polynomial kernel")</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co">plt.tight_layout()</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co">plt.draw() """</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>' # Visualisation des frontières de décision (svm_source.py)\ndef f_linear(xx):\n    return clf_linear.predict(xx.reshape(1, -1))\n\ndef f_poly(xx):\n    return clf_poly.predict(xx.reshape(1, -1))\n\n# Création des graphiques comparatifs\nplt.ion()\nplt.figure(figsize=(15, 5))\n\n# Graphique 1 : données originales\nplt.subplot(131)\nplot_2d(X, y)\nplt.title("iris dataset")\n\n# Graphique 2 : frontière avec noyau linéaire\nplt.subplot(132)\nfrontiere(f_linear, X, y)\nplt.title("linear kernel")\n\n# Graphique 3 : frontière avec noyau polynomial\nplt.subplot(133)\nfrontiere(f_poly, X, y)\nplt.title("polynomial kernel")\n\nplt.tight_layout()\nplt.draw() '</code></pre>
</div>
</div>
<p>Ainsi, les graphiques confirment visuellement notre analyse précédente : les fronrières de décision pour les noyaux linéaire et polynomial sont identiques.</p>
<p>Nous voyons que la frontière de décision est une droite linéaire qui sépare l’espace en deux régions distinctes (bleue et orange). La distribution des données montre qu’il n’y a pas de courbure complexe visible, ce qui justifie que les noyaux polynomiaux de degré supérieurs n’ont pas été sélectionnés.</p>
<p>De plus, nous observons un chevauchement partiel entre les deux classes (les points bleus et oranges sont mélangés dans certaines zones) ce qui explique pourquoi les scores de classification ne sont pas parfaits ($75% et <span class="math inline">\(68\%\)</span>).</p>
<p><a id="part3" href=""></a></p>
</section>
</section>
<section id="mise-en-oeuvre---svm-gui" class="level2">
<h2 class="anchored" data-anchor-id="mise-en-oeuvre---svm-gui">3. Mise en oeuvre - SVM GUI</h2>
<section id="question-3." class="level3">
<h3 class="anchored" data-anchor-id="question-3.">3.1. Question 3.</h3>
<p>Dans cette question, nous nous basons sur une <a href="https://scikit-learn.org/1.2/auto_examples/applications/svm_gui.html">application</a> qui permet, en temps réel, d’évaluer l’impact du choix du noyau et du paramètre de régularisation <span class="math inline">\(C\)</span>.</p>
<p>Pour commencer, nous lançons le script svm_script.py. Ensuite, nous créons un dataset très déséquilibré avec <span class="math inline">\(35\)</span> points bleus (<span class="math inline">\(92\%\)</span>) et <span class="math inline">\(3\)</span> points noirs (<span class="math inline">\(8\%\)</span>) en essayant de marquer la différence entre la localisation des points bleus et noirs (tout en gardant des débordements).</p>
<div id="fig-svm" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-svm" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-c10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="graphiques/C10.png" class="img-fluid figure-img" data-ref-parent="fig-svm">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) C = 10
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-svm" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-c1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="graphiques/C1.png" class="img-fluid figure-img" data-ref-parent="fig-svm">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) C = 1
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-svm" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-c01" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="graphiques/C01.png" class="img-fluid figure-img" data-ref-parent="fig-svm">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) C = 0,1
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-svm" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-c001" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c001-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="graphiques/C001.png" class="img-fluid figure-img" data-ref-parent="fig-svm">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c001-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) C = 0,01
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Influence du paramètre C sur un dataset déséquilibré avec noyau linéaire
</figcaption>
</figure>
</div>
<p>Nous voyons dans la <a href="#fig-svm" class="quarto-xref">Figure&nbsp;1</a> que :</p>
<ul>
<li>Pour <span class="math inline">\(C = 10\)</span> : l’hyperplan est légèrement en diagonal et minimise les erreurs sur toutes les classes (les points noirs sont tous classés ensemble).</li>
<li>Pour <span class="math inline">\(C = 1\)</span> : l’hyperplan est en diagonale et fait un vrai compromis entre les deux classes. Comme celui avec <span class="math inline">\(C\)</span> plus élevé, il arrive bien à séparer à la fois les bleus et les noirs.</li>
<li>Pour <span class="math inline">\(C = 0,1\)</span> : l’hyperplan est quasiment à la verticale, il n’y a que deux points noirs qui sont ensemble et le troisième est mal classé.</li>
<li>Pour <span class="math inline">\(C = 0,01\)</span> : l’hyperplan est également à la verticale, il a l’air d’ignorer les points noirs et se contente de séparer les points bleus.</li>
</ul>
<p>Nous pouvons voir que les <span class="math inline">\(C\)</span> élevés (<span class="math inline">\(10\)</span> et <span class="math inline">\(1\)</span>) semblent proches, de mêmes que les <span class="math inline">\(C\)</span> faibles (<span class="math inline">\(0,1\)</span> et <span class="math inline">\(0,01\)</span>). Nous voyons que les premiers prennent bien en compte les points minoritaires et les classent de la bonne manière. A contrario, les deux derniers semblent très tolérant aux erreurs : comme les bleus sont majoritaires, ils optimisent uniquement pour eux et négligent les noirs.</p>
<p>Ainsi, nous pouvons en conclure que, lorsque nous diminuons <span class="math inline">\(C\)</span> sur un dataset déséquilibré avec un noyau linéaire, l’hyperplan se déplace pour favoriser la bonne classification de la classe majoritaire et pour maximiser la marge, au détriment de la classe minoritaire. Avec <span class="math inline">\(C\)</span> très faible, le modèle ignore presque complétement les points noirs.</p>
<p>Cela s’explique car le paramètre <span class="math inline">\(C\)</span> contrôle le coût des erreurs de classification. Avec <span class="math inline">\(C\)</span> faible, le modèle préfère un hyperplan simple (avec une grande marge) quitte à faire des erreurs. Sur des données déséquilibrés, ces erreurs affectent principalement la classe minoritaire car elle a moins d’influence sur l’optimisation.</p>
<p>Ce phénomène illustre donc un problème critique en apprentissage automatique sur données déséquilibrées. Lorsque <span class="math inline">\(C\)</span> diminue, le modèle privilégie une marge large (simplicité) au détriment de la précision sur la classe minoritaire.</p>
<p><a id="part4" href=""></a></p>
</section>
</section>
<section id="mise-en-oeuvre---classification-de-visages" class="level2">
<h2 class="anchored" data-anchor-id="mise-en-oeuvre---classification-de-visages">4. Mise en oeuvre - Classification de visages</h2>
<p>Dans cette partie, nous utilisons une <a href="http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz">base de données</a> extraite de “Labeled Faces in the Wild” afin d’exposer un problème de classification de visages.</p>
<p>Nous commençons donc par télécharger la base de données qui nous intéresse.</p>
<div id="246b5a4c" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Téléchargement de la base de données "Labeled Faces in the Wild"</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>lfw_people <span class="op">=</span> fetch_lfw_people(min_faces_per_person<span class="op">=</span><span class="dv">70</span>, resize<span class="op">=</span><span class="fl">0.4</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                              color<span class="op">=</span><span class="va">True</span>, funneled<span class="op">=</span><span class="va">False</span>, slice_<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                              download_if_missing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraction des données</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> lfw_people.images</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>n_samples, h, w, n_colors <span class="op">=</span> images.shape</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>target_names <span class="op">=</span> lfw_people.target_names.tolist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Puis, nous choisissons une paire de personnes à classer : Donald Rumsfeld et Colin Powell.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sélection de deux personnes à classifier</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> [<span class="st">'Donald Rumsfeld'</span>, <span class="st">'Colin Powell'</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Filtrage des images pour ne garder que ces deux personnes</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>idx0 <span class="op">=</span> (lfw_people.target <span class="op">==</span> target_names.index(names[<span class="dv">0</span>]))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>idx1 <span class="op">=</span> (lfw_people.target <span class="op">==</span> target_names.index(names[<span class="dv">1</span>]))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> np.r_[images[idx0], images[idx1]]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Création des étiquettes (0 pour Rumsfeld, 1 pour Powell)</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.r_[np.zeros(np.<span class="bu">sum</span>(idx0)), np.ones(np.<span class="bu">sum</span>(idx1))].astype(<span class="bu">int</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage d'un échantillon de 12 visages</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>plot_gallery(images, np.arange(<span class="dv">12</span>))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="cell-fig-galerie" class="cell quarto-layout-panel" data-execution_count="8" data-layout-ncol="1">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-galerie" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-galerie-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="script_files/figure-html/fig-galerie-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-galerie-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Exemple de 12 visages de notre base de données
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>Nous observons quelle personne entre les deux étudiées est la plus représentée dans notre jeu de données et à quelle proportion.</p>
<div id="a431a2d2" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Code supplémentaire de vérirication/interprétation</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier la distribution des classes</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>unique, counts <span class="op">=</span> np.unique(y, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>class_distrib <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(unique, counts))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des résultats</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Distribution des classes :"</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>names[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> : </span><span class="sc">{</span>class_distrib[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> images (</span><span class="sc">{</span>class_distrib[<span class="dv">0</span>]<span class="op">/</span><span class="bu">len</span>(y)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>names[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> : </span><span class="sc">{</span>class_distrib[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> images (</span><span class="sc">{</span>class_distrib[<span class="dv">1</span>]<span class="op">/</span><span class="bu">len</span>(y)<span class="op">*</span><span class="dv">100</span><span class="sc">:.1f}</span><span class="ss">%)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution des classes :
Donald Rumsfeld : 121 images (33.9%)
Colin Powell : 236 images (66.1%)</code></pre>
</div>
</div>
<p>Nous voyons qu’il y a <span class="math inline">\(357\)</span> images au total et que c’est Colin Powell qui est le plus représenté avec <span class="math inline">\(66,1\%\)</span> des images totales.</p>
<p>Nous continous en divisant les données en deux sous-ensembles : un ensemble d’entraînement (train) et un ensemble de test (test).</p>
<div id="30cb0d59" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraction des caractéristiques (intensité lumineuse moyenne en niveaux de gris)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> (np.mean(images, axis<span class="op">=</span><span class="dv">3</span>)).reshape(n_samples, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalisation des caractéristiques (centrage et réduction)</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">-=</span> np.mean(X, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">/=</span> np.std(X, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Séparation train/test (50/50)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)     <span class="co"># ajout d'une graine pour reproductibilité</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.random.permutation(X.shape[<span class="dv">0</span>])</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>train_idx, test_idx <span class="op">=</span> indices[:X.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>], indices[X.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> X[train_idx, :], X[test_idx, :]</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>y_train, y_test <span class="op">=</span> y[train_idx], y[test_idx]</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>images_train, images_test <span class="op">=</span> images[</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    train_idx, :, :, :], images[test_idx, :, :, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="question-4." class="level3">
<h3 class="anchored" data-anchor-id="question-4.">4.1. Question 4.</h3>
<p>Nous cherchons maintenant à montrer l’influence du paramètre de régularisation <span class="math inline">\(C\)</span> en affichant l’erreur de prédiction.</p>
<p><a id="fig-cOpti" href=""></a></p>
<div id="cell-fig-cOpti" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Linear kernel ---"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Fitting the classifier to the training set"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition de la grille de valeurs de C à tester (de 10^-5 à 10^6)</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>Cs <span class="op">=</span> <span class="fl">10.</span> <span class="op">**</span> np.arange(<span class="op">-</span><span class="dv">5</span>, <span class="dv">6</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> []</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Boucle pour tester chaque valeur de C</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> C <span class="kw">in</span> Cs:</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Création d'un SVM avec noyau linéaire et paramètre C donné</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    clf_temp <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span>C)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entraînement du modèle sur les données d'entraînement</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    clf_temp.fit(X_train, y_train)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Évaluation sur les données de test et stockage du score</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    scores.append(clf_temp.score(X_test, y_test))</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Identification du meilleur C (celui qui maximise le score)</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> np.argmax(scores)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best C: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(Cs[ind]))</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation de l'évolution du score en fonction de C</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>plt.plot(Cs, scores)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Parametres de regularisation C"</span>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Scores d'apprentissage"</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">"log"</span>)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best score: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(np.<span class="bu">max</span>(scores)))</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicting the people names on the testing set"</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>--- Linear kernel ---
Fitting the classifier to the training set
Best C: 0.001</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="fig-copti" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-copti-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="script_files/figure-html/fig-copti-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-copti-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Evolution du score d’apprentissage en fontion du paramètre de régularisation
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best score: 0.9273743016759777
Predicting the people names on the testing set</code></pre>
</div>
</div>
<p>On peut voir dans la <a href="#fig-cOpti">Figure 3</a> qu’il y a <span class="math inline">\(92,7\%\)</span> de précision sur l’ensemble de test ce qui est une très bonne performance pour la classification de nos visages. Cela signifie que le modèle prédit correctement l’identité de la personne dans <span class="math inline">\(92\%\)</span> des cas.</p>
<p>De plus, nous voyons que la courbe montre trois zones distinctes : - Pour <span class="math inline">\(C &lt; 10^{-4}\)</span> : les scores sont faibles. La régularisation est excessive,le modèle est trop simple et sous-apprend. De plus, la marge doit être trop large ce qui permet trop d’erreurs. - Pour <span class="math inline">\(10^{-4} ≤ C ≤ 10^{-3}\)</span> : les scores augmentent jusqu’à un pic optimal (pour <span class="math inline">\(C = 0,001\)</span>). Nous avons le meilleur compromis biais-variance car le modèle capture la structure des données sans sous ou sur apprendre. - Pour <span class="math inline">\(C &gt; 10^{-3}\)</span> : les scores se stabilisent en un plateau. La performance n’augmente plus car le modèle est déjà suffisamment complexe. Donc, augmenter <span class="math inline">\(C\)</span> ne sert plus à rien et nous risquons de faire apparaître du sur-apprentissage.</p>
<p>Ainsi, le SVM avec <span class="math inline">\(C = 0.001\)</span> et le noyau linéaire offre une très bonne performance (<span class="math inline">\(92.7%\)</span>) pour cette tâche de reconnaissance faciale : il est suffisamment élevé pour permettre au modèle de capturer les différences entre les visages mais reste assez bas pour éviter de sur-ajuster les particularités de l’ensemble d’entraînement (expressions faciales, accessoires, éclairage, etc.).</p>
<p>De plus, nous pouvons en déduire qu’il y a probablement du bruit ou des variations dans les images (éclairage, expression, etc.) ce qui permet qu’un <span class="math inline">\(C\)</span> pas trop grand aide à ignorer ce bruit. En effet, le fait que la performance n’augmente pas pour des C plus grands suggère que le noyau linéaire capture bien la structure des données dans l’espace des caractéristiques.</p>
<p>Ainsi, à partir de ce classificateur optimal, nous cherchons maintenant à prédire les étiquettes pour les images <span class="math inline">\(X_test\)</span>.</p>
<div id="94fc5982" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Entraînement du modèle avec le meilleur C trouvé</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span>  svm.SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, C<span class="op">=</span>Cs[ind])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Prédiction sur l'ensemble de test</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"done in </span><span class="sc">%0.3f</span><span class="st">s"</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul du niveau de chance (si on prédit toujours la classe majoritaire)</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Chance level : </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> <span class="bu">max</span>(np.mean(y), <span class="fl">1.</span> <span class="op">-</span> np.mean(y)))</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy : </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> clf.score(X_test, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>done in 0.221s
Chance level : 0.6610644257703081
Accuracy : 0.9273743016759777</code></pre>
</div>
</div>
<p>Nous pouvons voir que nous avons un niveau de chance de <span class="math inline">\(66\%\)</span>, ce qui correspond à la précision qu’on obtiendrait en prédisant toujours la classe majoritaire (dans notre cas Colin Powell). C’est-à-dire qu’un classificateur naïf qui prédirait toujours Colin Powell aurait <span class="math inline">\(66\%\)</span> de précision. Cela correspond donc à notre borne inférieur : tout modèle doit faire mieux que ça.</p>
<p>Ensuite, nous voyons que nous obtenons une précision de <span class="math inline">\(92,7\%\)</span>, comme nous l’avions vu précédemment pour un <span class="math inline">\(C = 0,001\)</span>. En le comparant à notre niveau de base à absolument dépasser pour faire mieux qu’une prédiction naïve, nous voyons que la différence est très importante entre le deux. En effet, le modèle a réellement appris à distinguer les deux personnes et ne se contente pas de prédire la classe majoritaire.</p>
<p>Maintenant après avoir évalués quantitativement nos prédictions, nous avons les évaluer qualitativement à l’aide la librairie <code>matplotlib</code>.</p>
<p><a id="fig-heatmap" href=""></a></p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Création des titres pour chaque prédiction (correct/incorrect)</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>prediction_titles <span class="op">=</span> [title(y_pred[i], y_test[i], names)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                     <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_pred.shape[<span class="dv">0</span>])]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage d'une galerie de prédictions</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plot_gallery(images_test, prediction_titles)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des poids du classificateur sous forme d'image</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.reshape(clf.coef_, (h, w)))</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-heatmap" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-heatmap" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-heatmap-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-heatmap-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="script_files/figure-html/fig-heatmap-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-heatmap">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-heatmap-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Prédiction des étiquettes des 12 premiers visages
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-heatmap" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-heatmap-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-heatmap-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="script_files/figure-html/fig-heatmap-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-heatmap">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-heatmap-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Heatmap des poids du classificateur SVM linéaire
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-heatmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Évaluation qualitative des prédictions
</figcaption>
</figure>
</div>
<p>La <a href="#fig-heatmap">galerie d’images</a> permet d’évaluer visuellemtn les performances du modèles. On peut voir que la majorité des visages sont correctement classés (seulement <span class="math inline">\(2\)</span> erreurs sur les prédictions de Powell, ce qui correspond ici à environ <span class="math inline">\(83\%\)</span> de prédiction correcte). On voit également que le modèle a réussit à identifier les personnes mêmes avec des variations comme les expressions faciales, les angles de vue, les conditions d’éclairage ou encore la présence/absence de lunettes.</p>
<p>La <a href="#fig-heatmap">deuxième image</a> montre une heatmap, qui indique les poids du modèle SVM linéaire sous forme d’image :</p>
<ul>
<li>Les zones jaunes : indiquent les caractéristiques de la première classe (Colin Powell).</li>
<li>Les zones bleus foncées : indiquent les caractéristiques de la deuxième classe (Donald Rumself).</li>
<li>Les zones turquoise : indiquent que les pixels sont peu disciminant et n’aide pas à identifier la personne (poids proches de <span class="math inline">\(0\)</span>).</li>
</ul>
<p>Plus spécifiquement, nous voyons sur notre image qu’il y a des tâches jaunes principalement au centre de la photo ce qui pourrait correspondre aux zones du nez et des yeux. De plus, nous voyons un tâche bleu foncée en dessous de celles jaunes qui semble être la zone de la bouche ou du menton, et qui permet d’identifier la seconde personne. Toutes ces zones décrites sont celles qui permettent le mieux d’identifier si nous sommes en présence de Colin Powell ou de Donald Rumself. Ainsi, en se basant sur le turquoise, nous pouvons voir que l’arrière plan n’aide pas à discriminer la personne dans notre modèle, ce qui est cohérent car nous avons vu qu’il changeait sur chaque photographie.</p>
<p>Ainsi, nous pouvons dire que le SVM linéaire a appris à se concentrer sur les régions centrales du visage qui contiennent effectivement le plus d’informations discriminantes. Le fait que les poids les plus élevés soient localisés et non diffus suggère que le modèle semble avoir identifié des patterns cohérents plutôt que du bruit aléatoire. De plus, il nous semble distinguer un visage dans la heatmap ce qui appuie cette dernière conclusion.</p>
</section>
<section id="question-5." class="level3">
<h3 class="anchored" data-anchor-id="question-5.">4.2. Question 5.</h3>
<p>Nous allons maintenant ajouter <span class="math inline">\(300\)</span> variables de nuisance afin de vérifier si la performance chute bien. Cela est dû car le nombre de variables à nombre de points d’apprentissage fixé augmente.</p>
<div id="f1749ae4" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fonction pour entraîner et évaluer un SVM avec validation croisée.</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_svm_cv(_X, _y):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ajout de la graine</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Permutation aléatoire des indices pour mélanger les données</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    _indices <span class="op">=</span> np.random.permutation(_X.shape[<span class="dv">0</span>])</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Séparation en 50% train / 50% test</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    _train_idx, _test_idx <span class="op">=</span> _indices[:_X.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>], _indices[_X.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extraction des sous-ensembles</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    _X_train, _X_test <span class="op">=</span> _X[_train_idx, :], _X[_test_idx, :]</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    _y_train, _y_test <span class="op">=</span> _y[_train_idx], _y[_test_idx]</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Configuration de la recherche par grille (5 valeurs de C entre 0.001 et 1000)</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    _parameters <span class="op">=</span> {<span class="st">'kernel'</span>: [<span class="st">'linear'</span>], <span class="st">'C'</span>: <span class="bu">list</span>(np.logspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">5</span>))}</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    _svr <span class="op">=</span> svm.SVC()</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    _clf_linear <span class="op">=</span> GridSearchCV(_svr, _parameters)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Entraînement avec sélection automatique du meilleur C</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    _clf_linear.fit(_X_train, _y_train)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Affichage des performances</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Generalization score for linear kernel: </span><span class="sc">%s</span><span class="st">, </span><span class="sc">%s</span><span class="st"> </span><span class="ch">\n</span><span class="st">'</span> <span class="op">%</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>          (_clf_linear.score(_X_train, _y_train), _clf_linear.score(_X_test, _y_test)))</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Score sans variable de nuisance"</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>run_svm_cv(X, y)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Score avec variable de nuisance"</span>)</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Nombre de caractéristiques originales</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Génération de 300 variables dde nuisance (loi gaussienne)</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> sigma <span class="op">*</span> np.random.randn(n_samples, <span class="dv">300</span>, ) </span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Concaténation des données originales avec le bruit</span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>X_noisy <span class="op">=</span> np.concatenate((X, noise), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Permutation pour mélanger les lignes</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>) <span class="co"># graine</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>X_noisy <span class="op">=</span> X_noisy[np.random.permutation(X.shape[<span class="dv">0</span>])]</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>run_svm_cv(X_noisy, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Score sans variable de nuisance
Generalization score for linear kernel: 1.0, 0.9273743016759777 

Score avec variable de nuisance
Generalization score for linear kernel: 1.0, 0.6368715083798883 
</code></pre>
</div>
</div>
<p>Nous avons donc ajouté <span class="math inline">\(300\)</span> variables de nuisances générées à partir d’un bruit gaussien de variance <span class="math inline">\(\sigma = 1\)</span>. Les résultats montrent que le modèle mémorise toujours bien les données d’entraînement (<span class="math inline">\(1.0\)</span> donc <span class="math inline">\(100\%\)</span>) mais est un signe de sur-apprentissage. De plus, la précision sur le test chute de <span class="math inline">\(33,5\%\)</span> pour passer à <span class="math inline">\(59,2\%\)</span> ce qui cause, en plus, une énorme différence entre le score de nos données de train et celle de test et montre que le modèle ne généralise plus. Enfin, nous voyons que ce modèle est moins performant que le niveau de chance, c’est-à-dire qu’il vaut mieux toujours prédire la classe majoritaire plutôt qu’utiliser ce modèle qui va se tromper plus de fois.</p>
<p>Donc, le SVM linéaire tente d’utiliser toutes les variables (signal et bruit) car il ne peut pas distinguer automatiquement les variables utilies du bruit impliquant que les <span class="math inline">\(300\)</span> variables de bruits noient les centaines de variables utiles. Ainsi, le ratio signal/bruit devient défavorable et conduit notre modèle à avoir une performance inférieure au hasard.</p>
</section>
<section id="question-6." class="level3">
<h3 class="anchored" data-anchor-id="question-6.">4.3. Question 6.</h3>
<p>Afin de remédier au problème de données bruitées que nous avons observés lors de la questions précédente, nous allons améliorer la prédiction à l’aide d’une méthode de réduction de dimension. Cette méthode est l’Analyse en Composantes Principales (ACP) qui projette les données dans un espace de dimension réduite.</p>
<p>Cette méthode a plusieurs avantages dans notre cas :</p>
<ul>
<li>Filtrage du bruit : les variables de nuisance sont du bruit gaussin indépendant, donc elles ont une variable faible et aléatoire. Les composantes principales capturent d’abord la structure systématique (ici les visages) et donc le bruit se retrouve dans les composantes de faible variance et est éliminé.</li>
<li>Concentration de l’information : les <span class="math inline">\(n\)</span> premières composantes capturent un certain pourcentage de la variance totale (nous allons le voir par la suite dans le \hyperref{tableau récapitulatif}). Cette variance correspond principalement aux vrais caractéristiques faciales. Ainsi, on passe de plus de <span class="math inline">\(400\)</span> dimension à <span class="math inline">\(20\)</span>, donc le ration entre le signal et le bruit est nettement amélioré.</li>
</ul>
<p>Nous testons différentes valeurs de <span class="math inline">\(n\)</span> composantes pour pouvoir les comparer entre elles et identifier le nombre optimal de composantes princpales. Le choix de <span class="math inline">\(n\)</span> est très important et nous allons essayer de voir son ordre de grandeur optimal car trop peu de composants et on perd du signal utile mais trop de composant et on conserve du bruit.</p>
<p>Nous avons écrit le code suivant pour un <span class="math inline">\(n = 20\)</span> et l’avons ensuite modifié en changeant juste ce paramètre.</p>
<div id="f8665372" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">""" # Décommenter le code pour le faire tourner (attention, environ 20 minutes de chargement)</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">print("Score apres reduction de dimension")</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Nombre de composantes principales à conserver</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">n_components = 20  # jouer avec ce parametre</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Création et ajustement du modèle ACP sur les données bruitées</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">pca = PCA(n_components=n_components, random_state=42).fit(X_noisy)</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Projection des données dans le nouvel espace réduit</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">X_noisy_pca = pca.transform(X_noisy)</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Évaluation du modèle sur les données transformées</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">run_svm_cv(X_noisy_pca, y) """</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>' # Décommenter le code pour le faire tourner (attention, environ 20 minutes de chargement)\n\nprint("Score apres reduction de dimension")\n\n# Nombre de composantes principales à conserver\nn_components = 20  # jouer avec ce parametre\n\n# Création et ajustement du modèle ACP sur les données bruitées\npca = PCA(n_components=n_components, random_state=42).fit(X_noisy)\n\n# Projection des données dans le nouvel espace réduit\nX_noisy_pca = pca.transform(X_noisy)\n\n# Évaluation du modèle sur les données transformées\nrun_svm_cv(X_noisy_pca, y) '</code></pre>
</div>
</div>
<p>Nous avons obtenu les scores suivants :</p>
<div id="tbl-pca" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Impact du nombre de composantes de l’ACP sur les scores du modèle de classification
</figcaption>
<div aria-describedby="tbl-pca-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Nombre de composantes</th>
<th style="text-align: center;">Score Train</th>
<th style="text-align: center;">Score Test</th>
<th style="text-align: center;">Écart</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0,635</td>
<td style="text-align: center;">0,687</td>
<td style="text-align: center;">0,52%</td>
</tr>
<tr class="even">
<td style="text-align: center;">5</td>
<td style="text-align: center;">0,635</td>
<td style="text-align: center;">0,687</td>
<td style="text-align: center;">0,52%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">10</td>
<td style="text-align: center;">0,635</td>
<td style="text-align: center;">0,687</td>
<td style="text-align: center;">0,52%</td>
</tr>
<tr class="even">
<td style="text-align: center;">15</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">20</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">%</td>
</tr>
<tr class="even">
<td style="text-align: center;">25</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">30</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">%</td>
</tr>
<tr class="even">
<td style="text-align: center;">50</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">0,</td>
<td style="text-align: center;">x.x%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">100</td>
<td style="text-align: center;">0,843</td>
<td style="text-align: center;">0,570</td>
<td style="text-align: center;">2,73%</td>
</tr>
<tr class="even">
<td style="text-align: center;">200</td>
<td style="text-align: center;">1,000</td>
<td style="text-align: center;">0,603</td>
<td style="text-align: center;">3,97%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Donc, nous pouvons voir que l’ACP démontre son efficacité comme technique de débruitage et de réduction de dimension. En projetant les données bruitées dans un sous-espace de dimension <span class="math inline">\(??\)</span>, elle élimine les variables parasites tout en préservant les caractéristiques discriminantes des visages. Ce résultat illustre un principe important en machine learning : plus de variables n’est pas toujours mieux (overfitting).</p>
</section>
<section id="question-7." class="level3">
<h3 class="anchored" data-anchor-id="question-7.">4.4. Question 7.</h3>
<p>Il existe un biais dans notre prétraitement des données. En effet, au niveau de la question 4, la standardisation est effectuée sur l’ensemble complet des données avant la séparation en un échantillon d’entraînement et un autre de test. Donc, cela pose problème car les statistiques (moyenne et écart-type) sont calculées en incluant les données de test. Ainsi, le modèle a indirectement accès à des informations de l’échantillon de test pendant l’entraîbement, ce qui crée une fuite d’information. Donc, les performances mesurées sont surestimées car le modèle bénéficie d’information qu’il ne devrait pas avoir en situation réelle.</p>
<p>La bonne pratique serait de standardiser en utilisant uniquement les données, et statistiques associées, de l’échantillon d’entraînement.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">5. Conclusion</h2>
</section>
<section id="sources" class="level2">
<h2 class="anchored" data-anchor-id="sources">6. Sources</h2>
<p>Afin de réaliser ce TP, nous nous sommes basés sur plusieurs sources. Tout d’abord, nous avons utilisé la base de code donnée par B.Bensaid, B. Charlier et J. Salmon. De plus, nous avons utilisé le fichier définissant des fonctions <code>svm_source.py</code> écrit par J. Salmon, A. Gramfort et C. Vernade.</p>
<p>Ensuite, afin de réaliser la <a href="#part3">partie 3</a>, nous nous sommes servis du code disponible via <a href="https://scikit-learn.org/1.2/auto_examples/applications/svm_gui.html">ce lien</a> et écrit par P. Prettenhoer. En ce qui concerne la <a href="#part4">partie 4</a>, nous nous sommes servis de la base de données disponible via <a href="https://scikit-learn.org/0.19/datasets/labeled_faces.html">ce lien</a>.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>